{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "CSC420_2021_Tutorial_02_B.Taati.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "accelerator": "TPU",
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "interpreter": {
      "hash": "effbf8fe4a8c8b056efeb517037836616e8fe6d80daa0c0e938836118c9d2698"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Tutorial 2\n",
        "\n",
        "#CSC420 - Fall 2021\n",
        "\n",
        "#Babak Taati"
      ],
      "metadata": {
        "id": "sRevpOVFhbJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image"
      ],
      "outputs": [],
      "metadata": {
        "id": "hWLjLrVmfOdo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# install OpenCV\r\n",
        "!pip install opencv-python\r\n",
        "import cv2"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q1exTeIU3TyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**image gradients**"
      ],
      "metadata": {
        "id": "0I_nEd7KvRhT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# image gradients\r\n",
        "img = cv2.imread('./images/window.jpg') # READS IN NUMPY ARRAY\r\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "laplacian = cv2.Laplacian(gray, cv2.CV_64F)\r\n",
        "\r\n",
        "fig = plt.figure(figsize=(15,15))\r\n",
        "ax1 = fig.add_subplot(121)\r\n",
        "ax2 = fig.add_subplot(122)\r\n",
        "\r\n",
        "ax1.imshow(gray,cmap = 'gray')\r\n",
        "ax1.title.set_text('Original'), ax1.set_xticks([]), ax1.set_yticks([])\r\n",
        "ax2.imshow(laplacian,cmap = 'gray')\r\n",
        "ax2.title.set_text('Laplacian'), ax2.set_xticks([]), ax2.set_yticks([])"
      ],
      "outputs": [],
      "metadata": {
        "id": "WjH9TECdRAnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(7,7))\n",
        "#median = cv2.medianBlur(gray, 5)\n",
        "blur = cv2.GaussianBlur(gray,(5,5),1)\n",
        "plt.imshow(blur, cmap = 'gray')\n",
        "plt.xticks([]), plt.yticks([])\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "3DiC0D6hL_wr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# smooth first, then Laplacian\n",
        "\n",
        "laplacian = cv2.Laplacian(blur, cv2.CV_64F)\n",
        "\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "\n",
        "ax1.imshow(gray,cmap = 'gray')\n",
        "ax1.title.set_text('Original'), ax1.set_xticks([]), ax1.set_yticks([])\n",
        "ax2.imshow(laplacian,cmap = 'gray')\n",
        "ax2.title.set_text('Laplacian'), ax2.set_xticks([]), ax2.set_yticks([])"
      ],
      "outputs": [],
      "metadata": {
        "id": "b8NzOLJJLLhq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# same thing (or is it?!)\n",
        "\n",
        "L = [[0,1,0],[1,-4,1],[0,1,0]]\n",
        "L = np.asanyarray(L, np.float32)\n",
        "print(L)\n",
        "\n",
        "dst = cv2.filter2D(blur,-1,kernel=L)\n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(dst, cmap = 'gray')\n",
        "plt.xticks([]), plt.yticks([])"
      ],
      "outputs": [],
      "metadata": {
        "id": "1fNcNHQgrHma"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print([laplacian.min(), laplacian.max()])\n",
        "print([dst.min(), dst.max()])\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "CWjz7OiZv0M9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "moral of the story: if there's a function that does what you need, use that function!"
      ],
      "metadata": {
        "id": "6iuc-dgYh0r_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "whos"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ong2V1qyv5kT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# solution:  use  ddepth=cv2.CV_64F\n",
        "\n",
        "dst = cv2.filter2D(blur,ddepth=cv2.CV_64F,kernel=L)\n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(dst, cmap = 'gray')\n",
        "plt.xticks([]), plt.yticks([])"
      ],
      "outputs": [],
      "metadata": {
        "id": "iz2T2qkdxpgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sobelx = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=5)\n",
        "sobely = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=5)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "ax1.imshow(sobelx,cmap = 'gray')\n",
        "ax1.title.set_text('Sobel X'), ax1.set_xticks([]), ax1.set_yticks([])\n",
        "ax2.imshow(sobely,cmap = 'gray')\n",
        "ax2.title.set_text('Sobel Y'), ax2.set_xticks([]), ax2.set_yticks([])\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "h2vBnPfhJ5Hr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "blended = cv2.addWeighted(src1=sobelx,alpha=0.5,src2=sobely,beta=0.5,gamma=0)\n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(blended, cmap = 'gray')\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "7JbzrVP1o-u3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "notice light and dark regions (+ive & -ive)"
      ],
      "metadata": {
        "id": "HZgkr6vIqE9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#grad_mag = (sobelx**2) + (sobely**2); # gradient magnitude\n",
        "#grad_mag = abs(sobelx**1) + abs(sobely**1); # gradient \n",
        "grad_mag = cv2.addWeighted(src1=abs(sobelx**1),alpha=0.5,src2=abs(sobely**1),beta=0.5,gamma=0)\n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(grad_mag,cmap='gray')\n",
        "plt.xticks([]), plt.yticks([])"
      ],
      "outputs": [],
      "metadata": {
        "id": "UxldPCO-SADg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print([sobelx.min(), sobelx.max()])  # why? \n",
        "print([grad_mag.min(), grad_mag.max()])  # why? "
      ],
      "outputs": [],
      "metadata": {
        "id": "FLLy6mC1X8EL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hist,bins = np.histogram(grad_mag,3660,[0,3660])\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(hist)"
      ],
      "outputs": [],
      "metadata": {
        "id": "b2ehFqYdSlfF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(hist)\n",
        "plt.xlim([0,200])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Hb_-xXZgitv_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "th = grad_mag > 1000\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(th, cmap='gray')\n",
        "plt.xticks([]), plt.yticks([])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Xqx_vf49TuN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ret,th1 = cv2.threshold(grad_mag,1000,255,cv2.THRESH_BINARY) # try different numbers. Can you find a threshold that gets all the edges, but nothing else?\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(th1, cmap='gray')\n",
        "plt.xticks([]), plt.yticks([])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Kqs_HlkVqgMY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# edges (Canny)\n",
        "edges = cv2.Canny(gray, threshold1=75, threshold2=100)\n",
        "\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "ax1.imshow(gray, cmap = 'gray')\n",
        "ax1.title.set_text('Original Image'), ax1.set_xticks([]), ax1.set_yticks([])\n",
        "ax2.imshow(edges,cmap = 'gray')\n",
        "ax2.title.set_text('Edge Image'), ax2.set_xticks([]), ax2.set_yticks([])"
      ],
      "outputs": [],
      "metadata": {
        "id": "GxunpjiYKhmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bold text**#**more:** [OpenCV Python Tutorials](https://docs.opencv.org/4.5.2/d6/d00/tutorial_py_root.html)"
      ],
      "metadata": {
        "id": "el7VElGcA55W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's go through the ***Morphological Transformations***  tutorial \n",
        "(under ***Image Processing in OpenCV***)\n"
      ],
      "metadata": {
        "id": "yAElKlFWr6Vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "img = np.zeros(shape=(480,640),dtype=np.int16)\n",
        "cv2.putText(img,text='T E S T - O o',org=(100,100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale= 1,color=(255,255,255),thickness=4)\n",
        "cv2.putText(img,text='0 1 2 3 4 ',org=(150,200), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale= 2,color=(255,255,255),thickness=4)\n",
        "cv2.putText(img,text='5 6 7 8 9',org=(150,300), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale= 2,color=(255,255,255),thickness=4)\n",
        "ret, img = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(img, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "uwsto-s0r7Uo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kernel = np.ones((3,3),np.uint8)\n",
        "erosion = cv2.erode(img,kernel,iterations = 1)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(erosion, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "BKpcw_u0sBjS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kernel = np.ones((7,7),np.uint8)\n",
        "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(dilation, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "x34WNzmduZOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Are morphological transformations **linear**? \n",
        "\n",
        "linear transformations is a mapping from a vector space (***V***) to another vector space (***W***)\n",
        "\n",
        " ***f: V → W***\n",
        "\n",
        "For any two vectors ***u*** and ***v*** in ***V*** and any scalar *c*\n",
        "\n",
        "\n",
        "*   ***f(u+v) = f(u) + f(v)***\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "*   ***f***(*c* ***u***) = *c* ***f(u)***\n",
        "\n"
      ],
      "metadata": {
        "id": "i3ou6uglWYM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Closing = Dilation followed by Erosion**"
      ],
      "metadata": {
        "id": "GqYlQTENwe6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
        "close = cv2.erode(dilation,kernel,iterations = 1)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(close, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "-3LE11ChupjG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(closing, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "mD4OmXigvJU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Opening = erosion followed by dilation**"
      ],
      "metadata": {
        "id": "n96tyga8wncs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kernel = np.ones((3,3),np.uint8)\n",
        "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(opening, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "ou7ZB9w0wZLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Opening can get rid of 'salt' noise**"
      ],
      "metadata": {
        "id": "aeEsZhW3xAt_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# salt noise\n",
        "noisy_img = img.copy() \n",
        "R = np.random.rand(img.shape[0], img.shape[1]) > 0.70\n",
        "noisy_img[R] = 255\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(noisy_img, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "KSjwG-UIwt-Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kernel = np.ones((3,3),np.uint8)\n",
        "opening = cv2.morphologyEx(noisy_img, cv2.MORPH_OPEN, kernel)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(opening, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "txQso-tZxW6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# why?"
      ],
      "metadata": {
        "id": "aBcaESCAElG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Closing can get rid of 'pepper' noise**"
      ],
      "metadata": {
        "id": "RnLeP90gx6PI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# pepper noise\n",
        "noisy_img = img.copy() \n",
        "R = np.random.rand(img.shape[0], img.shape[1]) > 0.60\n",
        "noisy_img[R] = 0\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(noisy_img, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "sRVY0erDxo0Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kernel = np.ones((3,3),np.uint8)\n",
        "closing = cv2.morphologyEx(noisy_img, cv2.MORPH_CLOSE, kernel)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(closing, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "aUz9Z91Rx_mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* why?"
      ],
      "metadata": {
        "id": "OqB5UFYVEntW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Morphological Gradient = difference between dilation and erosion of an image\n",
        "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(gradient, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "r343jLbCyGRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   looks like ~ edge detection! (only for binary images)\n",
        "*   Can you think of other ways to find edges in a binary image?"
      ],
      "metadata": {
        "id": "VZZf46Z8y1jl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# try kernel shapes that are not square\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
        "kernel"
      ],
      "outputs": [],
      "metadata": {
        "id": "oT5lw50Qy6zR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(opening, cmap='gray')"
      ],
      "outputs": [],
      "metadata": {
        "id": "XXh0Dn1_zBFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Convolution is a linear operator\n",
        "* Are morphological operations linear?\n"
      ],
      "metadata": {
        "id": "d-kHGlfjSc9R"
      }
    }
  ]
}